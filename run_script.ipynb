{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('/nfs/turbo/umms-drjieliu/proj/medlineKG/GLKB_agent')\n",
    "import config\n",
    "# config.OPENAI_API_KEY = \"\"\n",
    "\n",
    "from Graph.graph import app\n",
    "from IPython.display import Image, display\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How is RFX6 related to MODY and T2D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = app.invoke({\"question\": question})\n",
    "print(state['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in state['context'].items():\n",
    "    print(f'{k}:')\n",
    "    print(v)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# graph qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('/nfs/turbo/umms-drjieliu/proj/medlineKG/GLKB_agent')\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from Chains.graph_qa_chain import get_graph_qa_chain\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from Prompts.prompt_template import create_few_shot_prompt\n",
    "import config\n",
    "import json\n",
    "\n",
    "neo4j_url = \"bolt://141.213.137.207:7687\"\n",
    "neo4j_user = 'neo4j'\n",
    "neo4j_pwd = 'password'\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=neo4j_url,\n",
    "    username=neo4j_user,\n",
    "    password=neo4j_pwd,\n",
    "    refresh_schema=False\n",
    ")\n",
    "\n",
    "# construct_schema({}, [], [])\n",
    "# schema = graph.get_structured_schema\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\", \n",
    "    temperature=0,\n",
    "    api_key=config.OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "schema = json.load(open('./graph_schema.json'))\n",
    "graph.structured_schema = schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'how many articles are published in 2022'\n",
    "\n",
    "prompt = create_few_shot_prompt()\n",
    "state = {\n",
    "    'question': question,\n",
    "    'query': question,\n",
    "    'schema': schema,\n",
    "    'prompt': prompt\n",
    "}\n",
    "graph_qa_chain = get_graph_qa_chain(state)\n",
    "res = graph_qa_chain.invoke(question)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# long time!\n",
    "import sys\n",
    "# sys.path.append('/nfs/turbo/umms-drjieliu/proj/medlineKG/GLKB_agent')\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from Chains.graph_qa_chain import get_graph_qa_chain\n",
    "# from Graph.state import GraphState\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chains import RetrievalQA, GraphCypherQAChain\n",
    "from Prompts.prompt_template import create_few_shot_prompt\n",
    "from Chains.decompose import question_planner\n",
    "\n",
    "neo4j_url = \"bolt://141.213.137.207:7687\"\n",
    "neo4j_user = 'neo4j'\n",
    "neo4j_pwd = 'password'\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=neo4j_url,\n",
    "    username=neo4j_user,\n",
    "    password=neo4j_pwd,\n",
    "    refresh_schema=False\n",
    ")\n",
    "\n",
    "# construct_schema({}, [], [])\n",
    "# schema = graph.get_structured_schema\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\", \n",
    "    temperature=0,\n",
    "    api_key=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json.dump(schema, open('/nfs/turbo/umms-drjieliu/proj/medlineKG/results/2024-08-14-GLKB_agent-hyhao/GLKB_agent/GLKB/graph_schema.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = json.load(open('./graph_schema.json'))\n",
    "graph.structured_schema = schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decomposer\n",
    "from typing import Literal, Optional, Tuple, List\n",
    "\n",
    "class SubQuery(BaseModel):\n",
    "    \"\"\"Decompose a given question/query into sub-queries\"\"\"\n",
    "\n",
    "    sub_query: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"A list of subqueries of the original questions.\",\n",
    "    )\n",
    "\n",
    "system = \"\"\"You are an expert at decomposing users' requests into Neo4j Cypher queries. \\\n",
    "\n",
    "For the given requests, decompose it into a series of step by step subqueries\n",
    "Each subquery can be a query to perform neo4j graph query.\n",
    "Always search for the node ids before specifying a new concept with its name in the graph.\n",
    "The result of the final subquery should be the final answer.\n",
    "\n",
    "Here is example:\n",
    "Question: Find all articles containing genes that regulate TP53 after 2010\n",
    "Answers:\n",
    "sub_query1 : Retrieve the node id of TP53 gene\n",
    "sub_query2 : Find all gene ids that regulate the node with the identified TP53 id.\n",
    "sub_query3 : Find articles related the identified gene ids published after 2010.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# llm_with_tools = llm.bind_tools([SubQuery])\n",
    "# parser = PydanticToolsParser(tools=[SubQuery])\n",
    "query_analyzer = prompt | llm.with_structured_output(SubQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Prompts.prompt_template import create_few_shot_prompt, create_few_shot_prompt_with_context\n",
    "from Chains.vector_graph_chain import get_vector_graph_chain\n",
    "from Chains.graph_qa_chain import get_graph_qa_chain, get_graph_qa_chain_with_context\n",
    "from Tools.parse_vector_search import DocumentModel\n",
    "# from Chains.decompose import query_analyzer\n",
    "from Graph.state import GraphState\n",
    "\n",
    "def retrieve_context(state: GraphState):\n",
    "    '''Returns a dictionary of at least one of the GraphState'''    \n",
    "    '''Retrieve context of each step according to their types'''\n",
    "\n",
    "    steps = state[\"steps\"]\n",
    "    \n",
    "    k = 3\n",
    "    vector_graph_chain = get_vector_graph_chain(k=k)\n",
    "    state['prompt'] = create_few_shot_prompt()\n",
    "    state['prompt_context'] = []\n",
    "    state['prompt_with_context'] = create_few_shot_prompt_with_context(state)\n",
    "    graph_qa_chain = get_graph_qa_chain(state)\n",
    "    graph_qa_chain_context = get_graph_qa_chain_with_context(state)\n",
    "\n",
    "    contexts = dict()\n",
    "\n",
    "    for step, qtype in zip(steps.steps, steps.query_types):\n",
    "        if qtype.datasource == \"vector search\":\n",
    "            chain_result = vector_graph_chain.invoke({\n",
    "                \"query\": step},\n",
    "            )\n",
    "            documents = [DocumentModel(**doc.dict()) for doc in chain_result['source_documents']]\n",
    "            extracted_data = [{\"title\": doc.extract_title(), \"abstract\":doc.extract_abstract(), \"pubmedid\": doc.metadata.article_id} for doc in documents]\n",
    "            contexts[step] = extracted_data\n",
    "        elif qtype.datasource == \"graph query\":\n",
    "            subqueries = query_analyzer.invoke(step).sub_query\n",
    "            for sub in subqueries:\n",
    "                if len(prompt_context) == 0: # no context\n",
    "                    res = graph_qa_chain.invoke(sub)\n",
    "                else:\n",
    "                    res = graph_qa_chain_context.invoke(sub)\n",
    "                state['prompt_context'].append((sub, res))\n",
    "                print((sub, res))\n",
    "            contexts[step] = res\n",
    "    return {'context': contexts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = create_few_shot_prompt()\n",
    "print(prompt.format(\n",
    "    question='How many articles are related to TP53',\n",
    "    query='How many articles are related to TP53',\n",
    "    schema=graph.schema,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\", openai_api_key=\"\")\n",
    "\n",
    "llm_transformer = LLMGraphTransformer(\n",
    "  llm=llm, \n",
    "  node_properties=[\"description\"],\n",
    "  relationship_properties=[\"description\"]\n",
    ")\n",
    "\n",
    "def process_text(text: str):\n",
    "    doc = Document(page_content=text)\n",
    "    return llm_transformer.convert_to_graph_documents([doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Insulin resistance is associated with a cluster of metabolic and hemodynamic abnormalities that lead to increased cardiovascular morbidity and mortality. In this review the main pathophysiological mechanisms and metabolic consequences of insulin resistance are summarized. The correlation between insulin resistance and cardiovascular disease and the practical utility of the concept of metabolic syndrome as a diagnostic tool are also discussed.'\n",
    "g = process_text(text)\n",
    "g = g[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from xml.etree import ElementTree as ET\n",
    "import time\n",
    "\n",
    "def get_pmcid_from_pmid(pmid):\n",
    "    # Base URL for the E-utilities elink tool\n",
    "    url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi\"\n",
    "    \n",
    "    # Parameters for the API request\n",
    "    params = {\n",
    "        \"dbfrom\": \"pubmed\",  # Source database is PubMed\n",
    "        \"db\": \"pmc\",         # Target database is PubMed Central\n",
    "        \"linkname\": \"pubmed_pmc\",  # Link between PubMed and PMC\n",
    "        \"id\": pmid,          # The PMID we want to query\n",
    "        \"retmode\": \"xml\"     # Return the results in XML format\n",
    "    }\n",
    "    \n",
    "    # Send the request to the NCBI E-utilities\n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    # Parse the XML response\n",
    "    tree = ET.fromstring(response.content)\n",
    "    \n",
    "    # Try to find the PMCID in the XML\n",
    "    pmcid = None\n",
    "    for linkset in tree.findall(\".//LinkSetDb\"):\n",
    "        if linkset.find(\"LinkName\").text == \"pubmed_pmc\":\n",
    "            pmcid_tag = linkset.find(\".//Link/Id\")\n",
    "            if pmcid_tag is not None:\n",
    "                pmcid = pmcid_tag.text\n",
    "                break\n",
    "    \n",
    "    if pmcid:\n",
    "        return pmcid\n",
    "    else:\n",
    "        return \"PMCID not found\"\n",
    "\n",
    "res = requests.get(\"https://hirnetwork.org/2021/wp-admin/admin-ajax.php?action=alm_get_posts&query_type=standard&id=&post_id=8433&slug=all-hirn-publications&canonical_url=https%253A%252F%252Fhirnetwork.org%252Fall-hirn-publications&posts_per_page=1500&page=0&offset=0&post_type=publication&repeater=default&seo_start_page=1&taxonomy=publication_category&taxonomy_terms=all&taxonomy_operator=IN&meta_key=consortia:pubmed_id:research_groups&meta_compare=EXISTS&meta_relation=OR&order=DESC&orderby=date\")\n",
    "\n",
    "if res.status_code == 200:\n",
    "    # Parse the page content\n",
    "    soup = BeautifulSoup(res.json()['html'], 'html.parser')\n",
    "    \n",
    "    # You need to inspect the HTML structure and find the tag where PubMed IDs are located\n",
    "    publications = []\n",
    "\n",
    "    # Find all rows\n",
    "    for row in soup.find_all('div', class_='row'):\n",
    "        # Extract the publication date (first <div class=\"col-sm-2\">)\n",
    "        pub_date = row.find_all('div', class_='col-sm-2')[0].get_text(strip=True)\n",
    "        \n",
    "        # Extract the consortium name (second <div class=\"col-sm-2\">)\n",
    "        consortium = row.find_all('div', class_='col-sm-2')[1].get_text(strip=True)\n",
    "        \n",
    "        # Extract the publication title and PubMed link\n",
    "        title_tag = row.find('p', class_='pub-title').find('a')\n",
    "        title = title_tag.get_text(strip=True)\n",
    "        pubmed_link = title_tag['href']\n",
    "        \n",
    "        # Extract the publication details (authors, journal info, PMID)\n",
    "        details = row.find('p').find_next_sibling('p').get_text(strip=True)\n",
    "        \n",
    "        # Append the extracted information as a dictionary\n",
    "        publications.append({\n",
    "            'Date': pub_date,\n",
    "            'Consortium': consortium,\n",
    "            'Title': title,\n",
    "            'PubMed Link': pubmed_link,\n",
    "            'Details': details\n",
    "        })\n",
    "\n",
    "    # Convert the list of dictionaries into a pandas DataFrame\n",
    "    df = pd.DataFrame(publications)\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {res.status_code}\")\n",
    "\n",
    "df['PMID'] = df['PubMed Link'].apply(lambda x: x.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmcids = []\n",
    "for i, pmid in enumerate(df['PMID']):\n",
    "    # print(i, pmid)\n",
    "    pmcids.append(get_pmcid_from_pmid(pmid))\n",
    "    time.sleep(2)\n",
    "df['PMCID'] = pmcids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/nfs/turbo/umms-drjieliu/proj/medlineKG/data/HIRN_publication/HIRN_publication_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/nfs/turbo/umms-drjieliu/proj/medlineKG/data/HIRN_publication/HIRN_publication_info.csv')\n",
    "df[df['PMCID']=='PMCID not found']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
